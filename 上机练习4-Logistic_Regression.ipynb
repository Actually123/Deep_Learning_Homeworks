{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae94c1b",
   "metadata": {},
   "source": [
    "# 逻辑斯蒂回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0aa1c",
   "metadata": {},
   "source": [
    "## 使用MNIST数据集中的0，1数据完成logistic regression 任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836e70a",
   "metadata": {},
   "source": [
    "### 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3b9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afec8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义是否使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 定义数据预处理方式\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc944971",
   "metadata": {},
   "source": [
    "利用框架自带数据集读取方式读取 MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262c53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download 第一次可设置为True\n",
    "trainset = tv.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e361f6a",
   "metadata": {},
   "source": [
    "从训练集中取出0、1标签的数据构成此次任务的训练集(train_input,train_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ab1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_label = [], []\n",
    "\n",
    "for cin, label in trainset:\n",
    "    if label in [0, 1]:\n",
    "        train_input.append(cin)\n",
    "        train_label.append(label)\n",
    "\n",
    "train_input = torch.stack(train_input)\n",
    "train_label = torch.tensor(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c457db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试数据集\n",
    "testset = tv.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddaa22",
   "metadata": {},
   "source": [
    "从测试集中取出0、1标签的数据构成此次任务的测试集(test_input,test_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3380db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_label = [], []\n",
    "\n",
    "for cin, label in testset:\n",
    "    if label in [0, 1]:\n",
    "        test_input.append(cin)\n",
    "        test_label.append(label)\n",
    "        \n",
    "test_input = torch.stack(test_input)\n",
    "test_label = torch.tensor(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec74a08",
   "metadata": {},
   "source": [
    " 创建自己的数据集，需要补充完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e68c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    创建自己的dataset类 继承torch.utils.data.Dataset。\n",
    "    Dataset wrapping data and target tensors.\n",
    "    Each sample will be retrieved by indexing both tensors along the first\n",
    "    dimension.\n",
    "    Arguments:\n",
    "        data_tensor (Tensor): contains sample data.\n",
    "        target_tensor (Tensor): contains sample targets (labels).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_tensor, target_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "\n",
    "    # 这个方法是必须要有的，用于按照索引读取每个元素的具体内容\n",
    "    def __getitem__(self, index):\n",
    "        # #return很关键，return回哪些内容，那么我们在训练时循环读取每个batch时，\n",
    "        # 就能获得哪些内容\n",
    "        return self.data_tensor[index], self.target_tensor[index]\n",
    "\n",
    "    ##这个函数也必须要写，它返回的是数据集的长度\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414fb91",
   "metadata": {},
   "source": [
    "定义训练批处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff14e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size 根据自己计算资源设计，shuffle设置为True，查询设置的原因。\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    TensorDataset(train_input, train_label),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    )\n",
    "# #shuffle参数用于控制数据的洗牌方式，当shuffle设置为True时，每次读取数据都会\n",
    "# 对数据进行随机洗牌，保证训练过程中数据的顺序是随机的，从而避免模型对某些特定\n",
    "# 顺序的数据过拟合。因此，设置shuffle=True可以提高模型的泛化能力\n",
    "\n",
    "# 测试集\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    TensorDataset(test_input, test_label),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd443dde",
   "metadata": {},
   "source": [
    "利用pytorch框架的nn.Module 模块完成logistic regression 模型的设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0681bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression(nn.Module):\n",
    "    '''\n",
    "        逻辑回归模型\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(logistic_regression, self).__init__()\n",
    "        ### 添加logistic regression层\n",
    "        self.linear = nn.Linear(28*28, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 计算图（1）数据维度拉长\n",
    "        #        （2）logistic regression层传播\n",
    "        #        （3）return输出（注意维度）\n",
    "        \n",
    "        # 数据维度拉长\n",
    "        x = x.view(-1, self.linear.in_features)\n",
    "        # 逻辑斯蒂层传播\n",
    "        output = self.linear(x)\n",
    "        # return输出\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd85b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "log_reg = logistic_regression().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a0918",
   "metadata": {},
   "source": [
    "设置损失函数及优化器。提示：使用binary cross entropy 损失函数，优化器可设置SGD、Adam等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f2cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用binary cross entropy损失函数\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 设置优化器\n",
    "optimizer = torch.optim.SGD(log_reg.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a43ef0",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3544019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮 loss: 1.3040272545814515\n",
      "识别准确率为：81.8439712524414%\n",
      "第2轮 loss: 1.200778603553772\n",
      "识别准确率为：92.90780639648438%\n",
      "第3轮 loss: 1.1122282963991166\n",
      "识别准确率为：97.54137420654297%\n",
      "第4轮 loss: 1.0353444460034371\n",
      "识别准确率为：99.38534545898438%\n",
      "第5轮 loss: 0.9679196089506149\n",
      "识别准确率为：99.57447052001953%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    sum_loss = 0.0\n",
    "    # 数据读取\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 模型输出\n",
    "        outputs = log_reg(inputs)\n",
    "        \n",
    "        # 定义loss\n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # loss反向传播\n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "\n",
    "    print('第{0}轮 loss: {1}'.format(epoch+1, sum_loss / 100))\n",
    "\n",
    "#  输出测试集准确率: 没有对测试集进行DataLoader，如果自己电脑配置不够，\n",
    "#尝试建立testloader 然后按照批量计算\n",
    "    with torch.no_grad():\n",
    "        test_outputs = log_reg(test_input.cuda())\n",
    "\n",
    "        test_predicted = torch.squeeze(test_outputs>=0.5).int()\n",
    "        \n",
    "        accuracy = (test_predicted.cpu() == test_label.int()).sum().float() / test_label.size()[0]\n",
    "        print('识别准确率为：{}%'.format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
